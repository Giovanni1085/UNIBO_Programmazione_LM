{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Formats\n",
    "\n",
    "One \"Swiss knife\" tool (or library) for each format:\n",
    "- XML: `BeautifoulSoup`\n",
    "- JSON: `json`\n",
    "- CSV: `csv`\n",
    "\n",
    "<img src='https://cdn-images-1.medium.com/max/1600/1*Emm10TxVEOvWqwF9oPJb1w.jpeg' width='300px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several Python libraries to parse XML but `BeautifulSoup` is somehow the swiss knife of XML parsing.\n",
    "\n",
    "It can parse HTML, XML, as well as ill-formed or broken XML documents (very useful for legacy XML or even SGML data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/altoxml/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get the path of XML files\n",
    "# we filter only files with XML extension\n",
    "# it can be useful to ignore e.g. `.DS_Store` files (under MacOS)\n",
    "\n",
    "xml_files = [\n",
    "    os.path.join(data_folder, file)\n",
    "    for file in os.listdir(data_folder)\n",
    "    if \".xml\" in file\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefixing a code cell's content with `!`\n",
    "# tells jupyter to execute it as a bash shell command\n",
    "# Here we use the command `head` to peek at the first 100 lines\n",
    "# of our XML file.\n",
    "\n",
    "!head -n 50 data/altoxml/27971740_1890-04-01_38_077_0_001.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(xml_files[0], 'r') as inpfile:\n",
    "    xml_doc = BeautifulSoup(inpfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the `<textblock>` element with `@id` = `Page1_Block2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_doc.find_all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_element = xml_doc.find_all(\n",
    "    'textblock',\n",
    "    attrs={'id': 'Page1_Block1'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by definition, there should exist excatly one element\n",
    "# with a given ID within the same document\n",
    "assert len(target_element) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same search logic applies to *any* XML attribute. \n",
    "\n",
    "Here we search for all `<composedblock>` with `@type` = `container`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_blocks = xml_doc.find_all(\n",
    "    'composedblock',\n",
    "    {'type': 'container'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding all XML elements with a given name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textline_elements = xml_doc.find_all('textline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = textline_elements[0].get('vpos')\n",
    "y = textline_elements[0].get('hpos')\n",
    "w = textline_elements[0].get('width')\n",
    "h = textline_elements[0].get('height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'The coordinates of the first line are : {x} (x), {y} (y), {h} (height), {w} (width)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating the XML tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el = xml_doc.find('styles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in el.children:\n",
    "    print(type(child), child.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = el.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el.previousSibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el.nextSibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise\n",
    "\n",
    "Let's now try to put all these things together to solve a real problem that you have already encountered, i.e. **turning a bunch of XML files into processable data**. Why this can be useful?\n",
    "\n",
    "(This exercise will take around 20-30 minutes to complete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def parse_alto(filepath):\n",
    "    \"\"\"\n",
    "    Convert each file to a dictionary with the\n",
    "    following keys: fulltext (list of lines), wordcount, filename.\n",
    "    \"\"\"\n",
    "    parsed_data = {}\n",
    "    \n",
    "    # add here your solution\n",
    "    # you'll need to parse the xml elements\n",
    "    # containing the information you are interested in\n",
    "    \n",
    "    # HINT: you may want to split the parsing of individual\n",
    "    # XML elements into dedicated functions that get called from\n",
    "    # `parse_alto()`\n",
    "    \n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once your function is in place, you should be\n",
    "# able to execute this cell, which applies your function\n",
    "# to all Alto files.\n",
    "\n",
    "data = [\n",
    "    parse_alto(xml_file)\n",
    "    for xml_file in xml_files\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON and CSV\n",
    "\n",
    "Via self learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For JSON see the [documentation](https://docs.python.org/3.11/library/json.html).\n",
    "* For CSV see the [documentation](https://docs.python.org/3.11/library/csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Python dictionary\n",
    "person = {\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}\n",
    "\n",
    "# Serialize: Convert Python dictionary to JSON string\n",
    "person_json = json.dumps(person)\n",
    "print(\"JSON string:\", person_json)\n",
    "\n",
    "# Deserialize: Convert JSON string back to Python dictionary\n",
    "person_dict = json.loads(person_json)\n",
    "print(\"Python dictionary:\", person_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Data to be written to the CSV file\n",
    "data = [\n",
    "    ['Name', 'Age', 'City'],\n",
    "    ['John Doe', '30', 'New York'],\n",
    "    ['Jane Doe', '25', 'Los Angeles']\n",
    "]\n",
    "\n",
    "# Open a CSV file for writing\n",
    "with open('stuff/example.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the data to the CSV file\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"Data written to example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Open the CSV file for reading\n",
    "with open('stuff/example.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Read and print each row\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
